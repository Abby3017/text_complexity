{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "import tarfile\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading corpus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to read data file using pandas from github repo\n",
    "url= 'https://github.com/scrosseye/CLEAR-Corpus/blob/main/CLEAR_corpus_final.xlsx?raw=True'\n",
    "myfile = requests.get(url)\n",
    "\n",
    "df=pd.read_excel(url, sheet_name='Data', engine='openpyxl')\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus of Sentences rated with Human Complexity Judgments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './../data/complexity_ds_en.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REALEC Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open tar.gz file name Exam2016.tar.gz in data folder and print all files in that that have .txt and .json extension, then store them in a list\n",
    "# all content of txt file as string and from json file read the content of key 'ielts', 'text' and store them as pandas dataframe\n",
    "\n",
    "file_path = './../data/Exam2016.tar.gz'\n",
    "count = 0\n",
    "dict_text = {}\n",
    "dict_json = {}\n",
    "data = []\n",
    "with tarfile.open(file_path, \"r:gz\") as tar:\n",
    "    count += 1\n",
    "    for tarinfo in tar:\n",
    "        if tarinfo.name.endswith(\".txt\") or tarinfo.name.endswith(\".json\"):\n",
    "            file_name = tarinfo.name\n",
    "            file_name = file_name.split('/')[1].split('.')[0]\n",
    "            with tar.extractfile(tarinfo) as f:\n",
    "                if tarinfo.name.endswith(\".txt\"):\n",
    "                    str_sentence = f.read()\n",
    "                    dict_text[file_name] = str_sentence\n",
    "                else:\n",
    "                    json_data = pd.read_json(f, orient='index').T\n",
    "                    dict_json[file_name] = json_data\n",
    "\n",
    "\n",
    "for key in dict_text.keys():\n",
    "    datum = []\n",
    "    sentence = dict_text[key]\n",
    "    json_data = dict_json[key]\n",
    "    datum = [sentence, json_data['ielts'][0], json_data['CEFR_level'][0], json_data['work_type'][0], json_data['year'][0]]\n",
    "    data.append(datum)\n",
    "\n",
    "df_pd = pd.DataFrame(data, columns=['sentence', 'ielts', 'CEFR_level', 'work_type', 'year'])\n",
    "df_pd = df_pd[df_pd['CEFR_level'] != '']\n",
    "df_pd.to_csv('./../data/Exam2016.csv', index=False, header=True)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MMLL - EFCAMDAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efcamdat_file_path = './../data/Final database (main prompts).xlsx'\n",
    "df = pd.read_excel(efcamdat_file_path, sheet_name='Sheet 1')\n",
    "efcamdat_df = df[['writing_id', 'cefr', 'cefr_numeric', 'level', 'grade', 'wordcount', 'mtld', 'text', 'text_corrected']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efcamdat_file_path = './../data/Final database (alternative prompts).xlsx'\n",
    "df = pd.read_excel(efcamdat_file_path, sheet_name='Sheet 1')\n",
    "efcamdat_df = df[['writing_id', 'cefr', 'cefr_numeric', 'level', 'grade', 'wordcount', 'mtld', 'text', 'text_corrected']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEWSELA Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10786 entries, 0 to 10785\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   slug         10786 non-null  object \n",
      " 1   language     10786 non-null  object \n",
      " 2   title        10786 non-null  object \n",
      " 3   grade_level  10786 non-null  float64\n",
      " 4   version      10786 non-null  int64  \n",
      " 5   filename     10786 non-null  object \n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 505.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "url = \"https://s3.amazonaws.com/newsela-research-corpora/newsela_article_corpus_with_scripts_2016-01-29.1.zip\"\n",
    "# read zip file from URL and also read the given csv file in the zip file\n",
    "response = requests.get(url)\n",
    "df = pd.DataFrame()\n",
    "with zipfile.ZipFile(BytesIO(response.content)) as z:\n",
    "    with z.open('newsela_article_corpus_2016-01-29/articles_metadata.csv') as f:\n",
    "        df = pd.read_csv(f)\n",
    "        print(df.info())\n",
    "    df['content'] = df['filename'].apply(lambda x: z.open('newsela_article_corpus_2016-01-29/articles/' + x).read())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
