{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import amrlib\n",
    "import pandas as pd\n",
    "import penman\n",
    "from   amrlib.graph_processing.amr_loading import load_amr_graph_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device      = 'cuda:0'  # or 'cpu'\n",
    "batch_size  = 8\n",
    "num_beams   = 8     # 1 ==> greedy\n",
    "num_ret_seq = 1     # 1 ==> return best sentence only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incoming_edge_count(variable, pgraph):\n",
    "    incomings = [t for t in pgraph.edges() if t.target==variable]\n",
    "    return len(incomings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stog = \"/cluster/home/abkumar/.local/lib/python3.10/site-packages/amrlib/model_stog/model_parse_xfm_bart_large-v0_1_0\"\n",
    "gtos = \"/cluster/home/abkumar/.local/lib/python3.10/site-packages/amrlib/gtos/model_generate_t5wtense-v0_1_0\"\n",
    "stog = amrlib.load_stog_model(model_dir=stog)\n",
    "gtos = amrlib.load_gtos_model(gtos, batch_size=batch_size, num_beams=num_beams, num_ret_seq=num_ret_seq)\n",
    "graphs = stog.parse_sents(['The system can parse sentences to AMR graphs or generate text from existing graphs.', 'This is a second running sentence.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('# ::snt This is a second running sentence.\\n(s / sentence\\n      :ARG1-of (r / run-04\\n            :ord (o / ordinal-entity\\n                  :value 2))\\n      :domain (t / this))',\n",
       " <Graph object (top=p) at 47710788569024>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs[1], pgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgraph = penman.decode(graphs[1])\n",
    "pgraph.metadata['snt'] = 'This is a second running sentence.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all variables and select appropriate candidates for the new top variable\n",
    "candidate_tops = pgraph.variables()\n",
    "candidate_tops.remove( pgraph.top )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'o', 'r', 't'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_tops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_tops = [v for v in candidate_tops if incoming_edge_count(v, pgraph) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['r']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_tops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Instance(source='s', role=':instance', target='sentence'),\n",
       " Instance(source='r', role=':instance', target='run-04'),\n",
       " Instance(source='o', role=':instance', target='ordinal-entity'),\n",
       " Instance(source='t', role=':instance', target='this')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pgraph.instances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s', 'r']\n",
      "['# ::snt This is a second running sentence.\\n(s / sentence\\n   :ARG1-of (r / run-04\\n               :ord (o / ordinal-entity\\n                       :value 2))\\n   :domain (t / this))', '# ::snt This is a second running sentence.\\n(r / run-04\\n   :ARG1 (s / sentence\\n            :domain (t / this))\\n   :ord (o / ordinal-entity\\n           :value 2))']\n"
     ]
    }
   ],
   "source": [
    " # Create the list to try, keeping the original top first\n",
    "new_tops = [pgraph.top] + candidate_tops\n",
    "print(new_tops)\n",
    "new_graphs = [penman.encode(pgraph, top=t) for t in new_tops]\n",
    "print(new_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'s': 'sentence', 'r': 'run-04', 'o': 'ordinal-entity', 't': 'this'}\n"
     ]
    }
   ],
   "source": [
    "# Get the mapping from top variables to the concept for debug\n",
    "var2concept = {t.source:t.target for t in pgraph.instances()}\n",
    "print(var2concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top: (s / sentence)\n",
      "    This is a second sentence running.\n",
      "top: (r / run-04)\n",
      "    This is the second sentence to run.\n"
     ]
    }
   ],
   "source": [
    "gen_sents, _ = gtos.generate(new_graphs, disable_progress=True)\n",
    "for sent, top in zip(gen_sents, new_tops):\n",
    "    print('top: (%s / %s)' % (top, var2concept[top]))\n",
    "    print('   ', sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/amrisi/amr-guidelines/blob/master/amr.md#amr-slogans ( regarding verbs and nouns)\n",
    "\n",
    "https://github.com/amrisi/amr-guidelines/blob/master/amr.md#amr-slogans (modality)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
